{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "batch_size = 32\n",
    "nb_categories = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/wenjian/data/'\n",
    "\n",
    "train_set_dir = data_root + 'wiki_crop_train/'\n",
    "val_set_dir = data_root + 'wiki_crop_val/'\n",
    "test_set_dir = data_root + 'wiki_crop_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                [0.229, 0.224, 0.225])]) # Imagenet standards\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                [0.229, 0.224, 0.225])]) # Imagenet standards\n",
    "\n",
    "# What should we do for test??????\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "train_set = ImageFolder(train_set_dir, transform=train_transform, target_transform=None)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_set = ImageFolder(val_set_dir, transform=val_transform, target_transform=None)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "test_set = ImageFolder(test_set_dir, transform=test_transform, target_transform=None)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \"\"\"\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e6032c461966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sure to load model 1? press enter to continue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Freeze model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input('Sure to load model 1? Press enter to continue')\n",
    "model = models.vgg16(pretrained=True)\n",
    "# Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class DotWithConstantVector(torch.nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(DotWithConstantVector, self).__init__()\n",
    "        self.c = c\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.c)\n",
    "        #return torch.bmm(x, c)\n",
    "\n",
    "value_vector = torch.ones((101, 1))\n",
    "value_vector = value_vector.new_tensor(range(101))\n",
    "\n",
    "\n",
    "# The original classifier[6]'s input features\n",
    "n_inputs = model.classifier[3].out_features\n",
    "# Add on classifier\n",
    "model.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 512), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(512, 101),                   \n",
    "                      nn.Softmax(),\n",
    "                      DotWithConstantVector(value_vector))\n",
    "model.summary()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "n_epochs = 10\n",
    "model.train()\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    for batch_id, (data, label) in enumerate(train_loader):\n",
    "        print('batch_id=', batch_id, '  ---label--- ', label)\n",
    "        # Generate predictions\n",
    "        out = model(data)\n",
    "        # Calculate loss\n",
    "        #print('---out--- ', out)\n",
    "        label = label.float()\n",
    "        loss = criterion(out, label)\n",
    "        print('loss=', loss)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "    time_end = time.time()\n",
    "    torch.save(model.state_dict(), '/home/wenjian/results')\n",
    "    with open('/home/wenjian/results/mylog.txt', 'a') as f:\n",
    "        f.write('epoch '+str(epoch)+' finished. Time consumed: ', time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.vgg16(pretrained=True)\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "# The original classifier[6]'s input features\n",
    "n_inputs = model2.classifier[3].out_features\n",
    "# Add on classifier\n",
    "model2.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 512), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(512, nb_categories),                   \n",
    "                      nn.Softmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: unbalanced dataset weights for loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_entropy_between_distributions(pred, target):\n",
    "    # The softmax part is not included in this function\n",
    "    entropy = 0.0\n",
    "    assert pred.shape != target.shape, 'shapes not match for cross_entropy_between_distributions'\n",
    "    for batch_index in range(pred.shape[0]):\n",
    "        for i in range(pred.shape[1]):\n",
    "            entropy += target[batch_index, i]*torch.log(pred[batch_index, i])\n",
    "    return entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.KLDivLoss()\n",
    "optimizer = optim.Adam(model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def from_one_hot(vector, gap=0.1):\n",
    "    n = argmax(vector)\n",
    "    return np.array(linear_shadow(n, gap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_shadow(label_batch, gap=0.2, nb_categories=101):\n",
    "    batch_size = label_batch.shape[0]\n",
    "    l = torch.zeros(batch_size, nb_categories, dtype= torch.float)\n",
    "    for i in range(batch_size):\n",
    "        label = torch.tensor(label_batch[i], dtype=torch.float)\n",
    "        for j in range(nb_categories):\n",
    "            l[i,j] = 1- abs(label-j)*gap\n",
    "            if l[i,j]<0:\n",
    "                l[i,j]=0\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(vectors):\n",
    "    # To normalize the distribution. Shape of the vectors are expected as (batch_size, vector_dim)\n",
    "    # Noted that the softmax function in Pytorch only work for float type tensor\n",
    "    return nn.functional.softmax(vectors, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id= 0   ---labels---  tensor([18, 20, 45, 19, 14, 18, 22, 19, 32, 33, 64, 21, 25, 47, 94, 18, 30, 67,\n",
      "        22, 27, 26, 70, 26, 16,  6, 18, 10, 50, 25, 77, 23, 15])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0142, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenjian/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id= 1   ---labels---  tensor([26, 50, 37, 40, 55, 21, 67, 17, 22, 27, 14, 26, 14, 22, 14, 16, 54, 32,\n",
      "        30, 21, 23, 45, 50,  6, 14, 21, 37, 18, 30, 20, 59, 12])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0100, grad_fn=<KlDivBackward>)\n",
      "batch_id= 2   ---labels---  tensor([63, 29, 51, 12, 19, 48, 49, 30, 15, 53, 20, 27, 21, 41, 22, 45,  6, 16,\n",
      "        44, 15, 22, 41, 61, 30, 62, 16, 15, 57, 27, 44, 37, 34])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0113, grad_fn=<KlDivBackward>)\n",
      "batch_id= 3   ---labels---  tensor([92, 11, 29, 36, 19, 58, 32, 26, 21, 27, 61, 51, 22, 16,  8, 16, 18, 30,\n",
      "        20, 23, 58, 50, 23, 22, 14, 18, 75, 26, 17, 19, 28, 63])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0090, grad_fn=<KlDivBackward>)\n",
      "batch_id= 4   ---labels---  tensor([21, 59, 16, 14, 36, 52, 50, 23, 25, 81, 14, 38, 17, 19, 25, 17, 19, 16,\n",
      "         0, 34, 49, 19, 26, 34, 22, 83, 48, 18, 38, 20, 14, 23])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0094, grad_fn=<KlDivBackward>)\n",
      "batch_id= 5   ---labels---  tensor([19, 28, 20, 59, 22, 21, 23, 64, 17, 30,  5, 21, 51, 40, 39, 32, 18, 86,\n",
      "        16, 27, 16, 27, 62, 25, 18, 62, 18, 41, 51, 23, 65, 39])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0067, grad_fn=<KlDivBackward>)\n",
      "batch_id= 6   ---labels---  tensor([53, 49, 47, 51, 17, 43, 76, 35, 23, 48, 64, 23, 17, 71, 28, 37, 17, 18,\n",
      "        21,  4, 17, 67, 22, 19, 29, 26, 11, 21, 54, 32, 15, 25])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0053, grad_fn=<KlDivBackward>)\n",
      "batch_id= 7   ---labels---  tensor([15, 30, 25, 21, 70, 42, 38,  2, 18, 55, 78, 21, 38, 36, 54, 21, 16, 18,\n",
      "        38, 41, 54, 17, 17, 21, 20, 66, 51, 19, 17, 28, 47, 21])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0061, grad_fn=<KlDivBackward>)\n",
      "batch_id= 8   ---labels---  tensor([17, 36, 19, 18, 27, 27, 40, 33, 51, 18, 30, 25, 15, 11, 22, 21, 27, 20,\n",
      "        63, 16, 27, 65, 65, 82, 21, 29, 71, 63, 17, 31, 53, 26])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0048, grad_fn=<KlDivBackward>)\n",
      "batch_id= 9   ---labels---  tensor([27, 16, 15, 36, 30, 23, 51, 21, 18, 66, 52, 23, 10, 23, 39, 31, 74, 70,\n",
      "        19, 20, 33, 37, 22, 44, 32, 15, 17, 63, 31, 41, 37, 14])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0035, grad_fn=<KlDivBackward>)\n",
      "batch_id= 10   ---labels---  tensor([30, 33, 17, 15, 36, 19, 75, 55, 26, 26, 42, 20, 18, 22, 18, 18, 15, 85,\n",
      "        34, 65, 22, 20, 38, 47, 25, 18, 18, 18, 21, 17, 19, 41])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0051, grad_fn=<KlDivBackward>)\n",
      "batch_id= 11   ---labels---  tensor([44, 69, 32, 21, 17, 56, 12, 61,  0, 50, 12, 27, 11, 20, 32, 16, 22, 20,\n",
      "        14, 22, 41, 30, 53, 30, 17, 22, 37, 49, 28, 38, 27, 14])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0021, grad_fn=<KlDivBackward>)\n",
      "batch_id= 12   ---labels---  tensor([21, 38, 17, 34, 53, 18, 22, 33, 16, 18, 29, 52, 17, 53, 59, 21, 17, 38,\n",
      "        21, 43, 38, 34, 16, 43, 15, 50, 32, 55, 40, 40, 54, 29])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0022, grad_fn=<KlDivBackward>)\n",
      "batch_id= 13   ---labels---  tensor([21, 14, 45, 58, 20, 19, 31, 17, 20, 22, 61, 15,  4, 65, 32, 42, 17, 20,\n",
      "        11, 19, 12, 31, 62, 41, 69, 22, 12, 15, 36,  6, 36, 19])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0113,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0039, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id= 14   ---labels---  tensor([23, 30, 63, 11, 29, 71, 15, 80, 18, 21, 19,  9, 53, 19, 95, 18, 17, 37,\n",
      "        47, 26, 81, 75, 16, 38, 22, 47, 16, 53, 19, 36, 31, 18])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0020, grad_fn=<KlDivBackward>)\n",
      "batch_id= 15   ---labels---  tensor([40, 16, 31, 52, 14, 16, 20, 44, 61, 29, 85, 16, 34, 27, 16, 52, 26, 21,\n",
      "        21, 53, 20, 31, 30, 65, 20, 19, 22, 21, 60, 15, 14, 17])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0016, grad_fn=<KlDivBackward>)\n",
      "batch_id= 16   ---labels---  tensor([14, 14, 25, 51, 16, 15, 56, 27, 12, 40, 53, 17, 38, 14, 47, 18, 28, 52,\n",
      "        62, 17, 77, 28, 21, 26, 28, 45, 26, 10, 30, 20, 19, 26])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0020, grad_fn=<KlDivBackward>)\n",
      "batch_id= 17   ---labels---  tensor([43, 43, 30, 16, 18, 20, 50, 19, 36, 19, 30, 23, 32, 17, 60, 16, 17, 78,\n",
      "        84, 33, 29, 15, 48, 72, 22, 19, 40, 10, 72, 56, 29,  6])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0113,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0010, grad_fn=<KlDivBackward>)\n",
      "batch_id= 18   ---labels---  tensor([18, 31,  2, 30, 64, 37, 26, 40, 72, 36, 17, 27, 20, 48, 14, 23, 18, 22,\n",
      "        66, 42, 72, 18, 12, 19, 23, 26, 70, 22, 16, 37, 42, 18])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0169, 0.0207, 0.0253,  ..., 0.0093, 0.0093, 0.0093],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0015, grad_fn=<KlDivBackward>)\n",
      "batch_id= 19   ---labels---  tensor([21, 21, 41, 27, 16, 12, 20, 36, 18, 37, 40, 36, 36, 10, 14, 21, 39, 23,\n",
      "        29, 40, 18, 18, 27, 22, 21, 22, 18, 12, 15, 14, 72, 29])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0018, grad_fn=<KlDivBackward>)\n",
      "batch_id= 20   ---labels---  tensor([58, 19, 28, 23, 17, 26, 28, 19, 15, 14, 75, 41,  6, 16, 15, 49, 37, 33,\n",
      "        42, 37, 17, 15, 31, 19, 47, 60, 21,  0, 28, 34, 66, 20])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0011, grad_fn=<KlDivBackward>)\n",
      "batch_id= 21   ---labels---  tensor([15, 28, 18, 54, 40, 39, 33, 10, 21, 25, 12, 29, 21, 20, 40, 20, 52, 28,\n",
      "        85, 31, 71, 81, 47, 18, 20, 26, 37, 26, 37, 28, 22, 33])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0009, grad_fn=<KlDivBackward>)\n",
      "batch_id= 22   ---labels---  tensor([58, 20, 21, 22, 44, 51, 23, 22, 76, 14, 17, 52, 26, 30, 23, 64, 27,  8,\n",
      "        19, 49, 23, 29, 38, 12, 37, 20, 48, 17, 16, 58, 18, 18])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0007, grad_fn=<KlDivBackward>)\n",
      "batch_id= 23   ---labels---  tensor([21, 23, 22, 20, 31, 21, 14, 12, 11, 28, 32, 63, 30, 67, 15, 43, 37, 42,\n",
      "        27, 56, 30, 27, 15, 19, 61, 56, 21, 22, 17, 32, 17, 18])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0008, grad_fn=<KlDivBackward>)\n",
      "batch_id= 24   ---labels---  tensor([ 0, 89, 41, 20, 41, 29, 44, 17, 39, 49, 17, 43, 19, 25, 44, 25, 12, 22,\n",
      "        22, 18, 72, 64, 47, 22, 19, 19, 12, 20, 32, 29, 66, 53])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0258, 0.0211, 0.0173,  ..., 0.0095, 0.0095, 0.0095],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0004, grad_fn=<KlDivBackward>)\n",
      "batch_id= 25   ---labels---  tensor([62, 48, 11, 27, 29, 12, 29, 43, 16, 17, 45, 26, 43, 38, 69, 10, 17, 28,\n",
      "        47, 32, 66, 15, 20, 35, 69, 27, 19, 86, 49, 15, 28, 23])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0008, grad_fn=<KlDivBackward>)\n",
      "batch_id= 26   ---labels---  tensor([23, 18, 30, 28, 51, 39, 21, 85, 80, 18, 20, 37, 48, 14, 55, 18, 45, 27,\n",
      "        16, 27, 41, 22, 82, 53, 39, 33, 15, 36, 26, 14, 43, 36])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0005, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id= 27   ---labels---  tensor([16, 22, 80, 23, 44, 33, 17, 36, 23, 22, 43, 15, 28, 17, 60, 15, 16, 61,\n",
      "        32, 59, 52, 75, 19, 54, 54, 44, 17, 21, 23, 41, 66, 41])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 28   ---labels---  tensor([50, 33, 56, 20, 43, 47,  6, 26, 16, 21, 16, 19, 21, 27, 23, 36, 29, 36,\n",
      "        31, 16, 36, 18, 31, 22, 28, 17, 16, 22, 82, 21, 18, 30])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0008, grad_fn=<KlDivBackward>)\n",
      "batch_id= 29   ---labels---  tensor([63, 34, 10, 67, 31, 45, 18, 21, 17, 53, 84, 44, 52, 23, 49, 23, 14, 54,\n",
      "        21, 15, 16, 18, 20, 22, 30, 21, 16, 31, 50, 14, 16, 14])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0005, grad_fn=<KlDivBackward>)\n",
      "batch_id= 30   ---labels---  tensor([25, 18, 55, 15, 26, 45, 28, 14, 41, 17, 58, 54, 19, 50, 18, 64, 62, 23,\n",
      "        62, 45, 16, 18, 18, 15, 50, 14, 26, 25, 26, 49, 61, 17])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0005, grad_fn=<KlDivBackward>)\n",
      "batch_id= 31   ---labels---  tensor([21, 38, 32, 20, 18, 17, 40, 61, 20, 21, 28, 12, 29, 21, 19, 18, 27, 22,\n",
      "        27, 16, 75, 14, 53, 18, 29, 56, 23, 21, 30, 40, 17, 40])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0004, grad_fn=<KlDivBackward>)\n",
      "batch_id= 32   ---labels---  tensor([21, 53, 10, 36, 53, 32, 78, 26, 12, 11, 21, 28, 25, 17, 27, 12, 16, 18,\n",
      "        47, 15, 82, 41, 31,  7, 25, 20, 34, 42, 15, 32, 49, 16])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 33   ---labels---  tensor([16, 18, 31, 39, 15, 54, 58, 38, 11, 26,  0, 25, 40, 18, 25, 64, 12, 59,\n",
      "        26, 26, 11, 27, 17, 31, 65, 59, 12, 49, 18, 25, 21, 47])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 34   ---labels---  tensor([56, 17, 91, 14, 28, 15, 29, 87, 76, 15, 42, 40, 22, 29, 54, 16, 25, 18,\n",
      "        17,  9, 46, 28, 49, 53, 18, 10, 38, 18, 17, 33, 25, 19])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0005, grad_fn=<KlDivBackward>)\n",
      "batch_id= 35   ---labels---  tensor([47, 19, 20, 43, 14, 50, 20, 19, 39, 25, 28, 41, 23, 18, 63, 22, 70, 52,\n",
      "        17, 40, 50, 20, 31, 62, 55, 20, 25,  2, 21, 10, 28, 89])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0005, grad_fn=<KlDivBackward>)\n",
      "batch_id= 36   ---labels---  tensor([18, 15, 17, 31, 66, 56, 12, 18, 19, 16, 34, 22, 27,  9, 22, 80, 56, 20,\n",
      "        15, 32, 58, 11, 45, 68, 31, 17, 32, 17, 64, 18, 25, 20])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 37   ---labels---  tensor([47, 23, 16, 41, 18, 21, 19, 30, 32, 11, 21, 52, 23, 36, 28, 21, 26, 20,\n",
      "        20, 23, 26, 28, 19, 15, 17, 17, 62, 18, 18, 44, 14, 33])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0002, grad_fn=<KlDivBackward>)\n",
      "batch_id= 38   ---labels---  tensor([ 1, 15, 25, 56, 29, 23, 19, 38, 22, 20, 25, 76, 22, 22, 21, 21, 15, 19,\n",
      "        51, 19, 26, 28, 14, 44, 45, 49, 16,  8, 12, 26, 86, 11])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0209, 0.0255, 0.0209,  ..., 0.0094, 0.0094, 0.0094],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0005, grad_fn=<KlDivBackward>)\n",
      "batch_id= 39   ---labels---  tensor([25, 56, 92, 48, 19, 16, 45, 47, 42, 74, 21, 32, 20, 54, 26, 48, 64, 37,\n",
      "        63, 28, 40, 16, 10, 18, 75, 17, 70, 56, 53, 32, 31, 29])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0004, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id= 40   ---labels---  tensor([70, 31, 38, 51, 92, 29, 26, 12, 14, 21, 20, 30, 19, 62, 38, 18, 31, 52,\n",
      "        15, 18, 17, 36, 66, 21, 27, 14, 77, 28, 32, 31, 17, 34])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 41   ---labels---  tensor([87, 83, 21, 63, 20, 52, 31, 20, 44, 14, 37, 61, 25, 65, 40, 73, 20, 12,\n",
      "        27, 67, 23, 28, 42, 27, 17, 19, 77, 84, 22, 36, 32, 17])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0002, grad_fn=<KlDivBackward>)\n",
      "batch_id= 42   ---labels---  tensor([25, 18, 47, 55, 42, 28, 18, 16, 71, 23, 16, 70, 47, 59, 42, 64, 19,  7,\n",
      "        75, 66, 30, 25, 33, 28, 17, 31, 40, 17, 33, 69, 16, 26])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 43   ---labels---  tensor([53, 53, 63, 15, 11, 58, 14, 12, 17, 15, 92, 26, 26, 49, 53, 44, 49, 27,\n",
      "        21, 19, 14, 29, 12, 26, 53, 25, 18, 65, 15, 73, 45, 16])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0004, grad_fn=<KlDivBackward>)\n",
      "batch_id= 44   ---labels---  tensor([56, 77, 43, 27, 33, 37, 62, 14, 76, 45, 15, 26, 30, 25, 49, 11, 18, 71,\n",
      "        31, 16, 16, 16, 16, 30, 26, 26, 18, 49, 21, 58, 44, 33])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 45   ---labels---  tensor([36, 22, 61, 20, 54, 52, 17, 26, 15, 76, 21, 37, 69, 18, 26, 29, 44, 23,\n",
      "        85, 32, 22, 26, 12, 22, 63, 70, 48, 22, 11, 16, 52, 40])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 46   ---labels---  tensor([12, 92, 12, 37, 30, 12, 62, 44, 86, 55, 32, 17, 21, 50, 41, 18, 18, 23,\n",
      "        25, 32, 17, 18, 53, 20, 34, 50, 49, 17, 26, 43, 15, 53])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 47   ---labels---  tensor([21, 20, 26, 71, 15, 10, 43, 40, 21, 19, 48, 37, 54, 16, 54, 56, 52, 29,\n",
      "        34, 37, 12, 48, 47, 26, 47, 16, 41, 34, 15, 65, 22, 50])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 48   ---labels---  tensor([28, 26, 52, 33, 32, 18, 23, 18, 19, 84, 39, 22, 67, 26, 44, 31, 14, 36,\n",
      "        17, 38, 26, 41, 20, 56, 19, 54, 27, 25, 18, 10, 15, 32])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 49   ---labels---  tensor([14, 17, 28, 66, 37, 69, 28, 18, 16, 29, 45, 17, 23, 19, 20, 33, 20, 58,\n",
      "        51, 16, 52, 49, 19, 25, 31, 69, 19, 49, 51, 39, 50, 11])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0004, grad_fn=<KlDivBackward>)\n",
      "batch_id= 50   ---labels---  tensor([43, 12, 19, 28, 33, 43, 13, 15, 42, 29, 17,  2, 44, 26, 16, 78, 23, 22,\n",
      "        20,  9, 17, 74, 22, 70, 65, 58,  8, 21, 29, 23, 28, 49])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0004, grad_fn=<KlDivBackward>)\n",
      "batch_id= 51   ---labels---  tensor([47, 16, 27, 16, 15,  0, 45, 15, 51, 41, 32, 30, 17, 15, 22, 11, 21, 77,\n",
      "        50, 80, 29, 22, 17, 42, 20, 14, 10, 48, 21, 17, 21, 23])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0002, grad_fn=<KlDivBackward>)\n",
      "batch_id= 52   ---labels---  tensor([78, 59, 53, 16, 45, 12, 42, 45, 43, 32, 67, 22, 17, 21, 22, 28, 25, 23,\n",
      "        43, 15, 21, 40, 27, 33, 25, 40, 54, 23, 14, 19, 22, 23])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id= 53   ---labels---  tensor([47, 39, 23, 10, 22, 30, 25, 15, 38, 28, 30, 20, 33, 11, 26, 31, 21, 23,\n",
      "        60, 29, 22, 18, 18, 18, 14, 18, 22,  8, 62, 41, 12, 27])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0004, grad_fn=<KlDivBackward>)\n",
      "batch_id= 54   ---labels---  tensor([19, 19, 22, 27, 18, 75, 21, 28, 15, 16, 15, 32, 62, 56,  9, 31, 19, 33,\n",
      "        20, 27, 41, 18, 17, 12, 23, 42, 49, 49, 47, 82, 38, 28])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 55   ---labels---  tensor([14, 22, 12, 64, 55, 16, 33, 16, 26, 21, 15, 29, 23, 62, 20, 29, 20, 40,\n",
      "        22, 23, 25, 34, 27, 31, 43, 21, 15, 18, 14, 76, 25, 72])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 56   ---labels---  tensor([66, 18, 71, 20, 44, 82, 20, 16, 29, 39, 80, 47, 40,  8, 17, 18, 44,  0,\n",
      "        18, 17, 15, 23, 82, 17, 22, 19, 21, 32, 17, 21, 50, 62])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0004, grad_fn=<KlDivBackward>)\n",
      "batch_id= 57   ---labels---  tensor([56, 12, 32, 15, 49, 54, 14, 33, 16, 25, 44, 14, 21, 61, 15, 32, 55, 38,\n",
      "        16, 89, 44, 22, 19, 17, 51, 14, 67, 18, 47, 49, 45, 32])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 58   ---labels---  tensor([59, 48, 47, 18, 14, 27, 16, 59, 23, 14, 52, 10, 22, 14, 60, 22, 19, 31,\n",
      "        23, 20, 17, 22, 44, 28, 80, 32, 21, 19, 17, 39, 23, 27])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 59   ---labels---  tensor([12, 33, 22, 18, 20, 29, 21, 15, 21, 16, 17, 50, 67, 67, 18, 66, 56, 29,\n",
      "        20, 28, 53, 47, 42, 17, 40, 48, 77, 34, 36, 17, 16, 18])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0002, grad_fn=<KlDivBackward>)\n",
      "batch_id= 60   ---labels---  tensor([44, 58, 17,  9, 15, 49, 74, 21, 25, 25, 50, 14, 19, 20, 14, 18, 20, 81,\n",
      "        17, 32, 20, 75, 69, 31, 36, 32, 25, 70, 39, 52, 29, 38])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0006, grad_fn=<KlDivBackward>)\n",
      "batch_id= 61   ---labels---  tensor([15, 60, 21, 20, 28, 14, 19, 33, 55, 61, 15, 11, 26, 27, 16, 16,  0, 41,\n",
      "        51, 56, 73, 28, 54, 17, 18, 72, 58, 25, 22, 21, 25, 17])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 62   ---labels---  tensor([16, 22, 28, 23, 16, 30, 14, 22, 17, 33, 22, 54, 18, 47, 36, 20, 19, 27,\n",
      "        23, 50, 17, 28, 38, 19, 27, 61, 15, 23, 17, 20, 23, 43])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0004, grad_fn=<KlDivBackward>)\n",
      "batch_id= 63   ---labels---  tensor([16, 56, 10, 16, 16, 51, 34, 20, 33, 14, 60, 44, 71, 27, 26, 52, 47, 22,\n",
      "        23, 23, 25, 19, 40, 23, 62, 30, 21, 41, 12, 20, 22, 40])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 64   ---labels---  tensor([23, 17, 25, 25, 34, 20, 36, 30, 28, 38, 25, 19, 10, 31, 19, 76, 28, 15,\n",
      "        30, 15, 27, 20, 16, 51, 31, 14, 51, 23, 15, 41, 47, 31])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0002, grad_fn=<KlDivBackward>)\n",
      "batch_id= 65   ---labels---  tensor([19, 17, 44, 27,  0, 75, 51, 50, 19, 23, 64, 61, 18, 19, 25, 18, 45, 50,\n",
      "        15, 36, 54, 17, 28, 19, 52, 17, 49, 17, 14, 18, 21, 42])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id= 66   ---labels---  tensor([22, 16, 17, 17, 33, 26, 63, 15, 45, 58, 36, 40, 11, 15, 54, 38, 47, 20,\n",
      "        22, 21, 26, 16, 36, 63, 33, 10, 42, 78, 56, 40, 14, 21])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 67   ---labels---  tensor([32, 69, 26, 14, 20, 24, 23, 54, 23, 47, 69, 43, 12, 47, 38, 22, 86, 27,\n",
      "        42, 21, 27, 44, 20, 20, 28, 22, 48, 58, 26, 37, 61, 17])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 68   ---labels---  tensor([23, 61,  7, 47, 81, 29, 22, 19, 31, 19, 21, 20, 55, 17, 25, 15, 14, 17,\n",
      "        16, 14, 17, 28, 67, 14, 16, 32, 16, 62, 44, 38, 20, 22])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0002, grad_fn=<KlDivBackward>)\n",
      "batch_id= 69   ---labels---  tensor([14, 23, 20, 21, 52, 18, 17, 18, 47, 14, 28, 40, 14, 20,  6, 18, 19, 20,\n",
      "        53, 75, 72, 12,  8, 52, 17, 20, 16, 60, 15, 18, 20, 27])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 70   ---labels---  tensor([27, 84, 62, 41, 58, 16, 29, 56, 19, 30, 20, 27, 20, 45, 26, 40, 33, 17,\n",
      "        21, 18, 12, 19, 18, 23, 37, 17, 15, 43, 28, 25, 31, 61])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 71   ---labels---  tensor([44, 84, 33, 26, 81, 25, 36, 51, 41, 23, 21, 20, 52, 27, 20, 26, 11, 33,\n",
      "        22, 23, 22, 33, 63, 30, 19, 17, 29, 18, 12, 21, 10, 38])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0003, grad_fn=<KlDivBackward>)\n",
      "batch_id= 72   ---labels---  tensor([32, 19, 62, 17, 33, 32, 33, 27, 47, 75, 16, 18, 33, 48, 20, 21, 36, 17,\n",
      "        27, 47, 49, 17, 31, 20, 65, 21, 18, 30, 36, 18, 19, 23])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0002, grad_fn=<KlDivBackward>)\n",
      "batch_id= 73   ---labels---  tensor([33, 39, 47, 43, 50, 43, 27, 56, 18, 62, 31, 16, 18, 29, 65, 43, 88, 16,\n",
      "        23, 27, 59, 17, 50, 18, 63, 28, 72, 29, 25, 51, 26, 16])\n",
      "label.shape  torch.Size([32])\n",
      "labels tensor([[0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        ...,\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092],\n",
      "        [0.0092, 0.0092, 0.0092,  ..., 0.0092, 0.0092, 0.0092]])\n",
      "loss= tensor(0.0002, grad_fn=<KlDivBackward>)\n",
      "batch_id= 74   ---labels---  tensor([36, 45, 39, 31, 22, 18, 27, 28, 52, 18, 15, 41, 40, 14, 69, 20, 55, 23,\n",
      "        11, 52, 43, 18, 70, 15, 21, 54, 20, 50, 14, 65, 16, 15])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-adc73e239c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_id='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'  ---labels--- '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mlog_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "model2.train()\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #running_corrects = 0\n",
    "    \n",
    "    for batch_id, (data, labels) in enumerate(train_loader):\n",
    "        print('batch_id=', batch_id, '  ---labels--- ', labels)\n",
    "        # Generate predictions\n",
    "        out = model2(data)\n",
    "        log_proba = torch.log(out)\n",
    "        # Calculate loss\n",
    "        #print('---out--- ', out)\n",
    "        \n",
    "        print('label.shape ', labels.shape)\n",
    "        labels = linear_shadow(labels)\n",
    "        labels = target_distribution(labels) # Normalize th distribution\n",
    "        print('labels', labels)\n",
    "        #labels = labels.float()\n",
    "        loss = criterion(log_proba, labels)\n",
    "        print('loss=', loss)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()*data.size(0)\n",
    "        #running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    time_end = time.time()\n",
    "    torch.save(model.state_dict(), '/home/wenjian/results2')\n",
    "    with open('/home/wenjian/results/mylog2.txt', 'a') as f:\n",
    "        f.write('epoch '+str(epoch)+' finished. Time consumed: ', time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = torch.randn(3, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9042,  0.1765,  0.5229,  0.2021,  0.5831],\n",
       "        [-0.5932,  0.9197,  0.0721, -1.7064,  0.4047],\n",
       "        [ 0.1000,  0.2682, -1.6858,  0.5479,  1.1514]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_try = torch.tensor([77, 51, 25, 2, 20, 14, 19, 21, 38, 26,  8, 61, 31, 17, 62, 32, 22, 15,\n",
    "        26, 42, 23, 30, 69, 27, 36, 49, 47,  9, 37, 86, 36, 54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([77, 51, 25,  2, 20, 14, 19, 21, 38, 26,  8, 61, 31, 17, 62, 32, 22, 15,\n",
       "        26, 42, 23, 30, 69, 27, 36, 49, 47,  9, 37, 86, 36, 54])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenjian/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "a = linear_shadow(tensor_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6000, 0.8000, 1.0000, 0.8000, 0.6000, 0.4000, 0.2000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3651,  1.9261, -1.6455, -1.2310,  1.0050],\n",
      "        [ 0.2845,  0.0487, -0.1906,  1.8214, -0.8511],\n",
      "        [ 0.9083,  0.2055, -0.2629, -0.2203, -2.3165]], requires_grad=True)\n",
      "tensor([1, 4, 0])\n",
      "tensor(1.4756, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "inputs = torch.randn(3, 5, requires_grad=True)\n",
    "print(inputs)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)\n",
    "output = loss(inputs, target)\n",
    "print(output)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3,4],[1,1,1,1]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_distribution(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
