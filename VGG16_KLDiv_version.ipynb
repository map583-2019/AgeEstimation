{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Estimation on IMDB-WIKI Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 with KLDiv-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import time\n",
    "\n",
    "batch_size = 32\n",
    "nb_categories = 101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/wenjian/data4/'\n",
    "\n",
    "train_set_dir = data_root + 'wiki_crop_train/'\n",
    "val_set_dir = data_root + 'wiki_crop_val/'\n",
    "test_set_dir = data_root + 'wiki_crop_test/'\n",
    "\n",
    "result_dir = '/home/wenjian/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation and augmentation for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                [0.229, 0.224, 0.225])]) # Imagenet standards\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                [0.229, 0.224, 0.225])]) # Imagenet standards\n",
    "\n",
    "# What should we do for test??????\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImageFolder(train_set_dir, transform=train_transform, target_transform=None)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_set = ImageFolder(val_set_dir, transform=val_transform, target_transform=None)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "test_set = ImageFolder(test_set_dir, transform=test_transform, target_transform=None)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input size of the image 224\\*224\\* 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Model: Simple CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=4))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=4))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=4))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(9*1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 101),\n",
    "            nn.Softmax())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print('---0---', x.shape)\n",
    "        x = self.layer1(x)\n",
    "        #print('---1---', x.shape)\n",
    "        x = self.layer2(x)\n",
    "        #print('---2---', x.shape)\n",
    "        x = self.layer3(x)\n",
    "        #print('---3---', x.shape)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Model\n",
    "VGGmodel = models.vgg16(pretrained=True)\n",
    "for param in VGGmodel.parameters():\n",
    "    param.requires_grad = False\n",
    "# The original classifier[6]'s input features\n",
    "n_inputs = VGGmodel.classifier[3].out_features\n",
    "# Add on classifier\n",
    "VGGmodel.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 512), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(512, nb_categories),                   \n",
    "                      nn.Softmax())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input_tensor):\n",
    "        return input_tensor.view(input_tensor.size(0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom cross entropy loss for smoothed target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_cross_entropy(pred, target):\n",
    "    # The softmax part is not included in this function\n",
    "    entropy = 0.0\n",
    "    assert pred.shape != target.shape, 'shapes not match for cross_entropy_between_distributions'\n",
    "    for batch_index in range(pred.shape[0]):\n",
    "        for i in range(pred.shape[1]):\n",
    "            entropy += target[batch_index, i]*torch.log(pred[batch_index, i])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the model as well as curresponding loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGmodel\n",
    "criterion = nn.KLDivLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_shadow(label_batch, gap=0.2, nb_categories=101):\n",
    "    batch_size = label_batch.shape[0]\n",
    "    l = torch.zeros(batch_size, nb_categories, dtype= torch.float)\n",
    "    for i in range(batch_size):\n",
    "        label = torch.tensor(label_batch[i], dtype=torch.float)\n",
    "        for j in range(nb_categories):\n",
    "            l[i,j] = 1- abs(label-j)*gap\n",
    "            if l[i,j]<0:\n",
    "                l[i,j]=0\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(vectors):\n",
    "    # To normalize the distribution. Shape of the vectors are expected as (batch_size, vector_dim)\n",
    "    # Noted that the softmax function in Pytorch only work for float type tensor\n",
    "    return nn.functional.softmax(vectors, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following part is inspired by https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epoch):\n",
    "    print('Start training...')\n",
    "    model.train()\n",
    "    log_interval = 10\n",
    "    losses = []\n",
    "    with open(result_dir + 'training_log.txt', 'a') as f: \n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            log_proba = torch.log(out)\n",
    "            labels = linear_shadow(labels)\n",
    "            labels = target_distribution(labels) # Normalize the distribution\n",
    "            loss = criterion(log_proba, labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "                f.write('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    print(\"Start validation...\")\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    diff = 0.0\n",
    "    print('---len val_loader--- ', len(val_loader.dataset))\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            \n",
    "            print('---target---', target.shape)\n",
    "            \n",
    "            out = model(data)\n",
    "            log_proba = torch.log(out)\n",
    "            labels = linear_shadow(target)\n",
    "            labels = target_distribution(labels) # Normalize th distribution\n",
    "            test_loss += criterion(log_proba, labels)\n",
    "            preds = out.argmax(dim=1, keepdim=True)\n",
    "            diff += nn.functional.l1_loss(preds.float(), target.float(), size_average=False) #nn.functional.l1_loss output the average l1 distance by default\n",
    "            \n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    diff /= len(val_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, average diff: {}\\n'.format(test_loss, diff))\n",
    "    with open(result_dir + 'validation_log.txt', 'a') as f:\n",
    "        f.write('\\nTest set: Average loss: {:.4f}, average diff: {}\\n'.format(test_loss, diff))\n",
    "    return test_loss, diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th epoch started...\n",
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenjian/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/4138 (0%)]\tLoss: 0.000561\n",
      "Train Epoch: 0 [320/4138 (8%)]\tLoss: 0.000249\n",
      "Train Epoch: 0 [640/4138 (15%)]\tLoss: 0.000244\n",
      "Train Epoch: 0 [960/4138 (23%)]\tLoss: 0.000244\n",
      "Train Epoch: 0 [1280/4138 (31%)]\tLoss: 0.000243\n",
      "Train Epoch: 0 [1600/4138 (38%)]\tLoss: 0.000243\n",
      "Train Epoch: 0 [1920/4138 (46%)]\tLoss: 0.000241\n",
      "Train Epoch: 0 [2240/4138 (54%)]\tLoss: 0.000238\n",
      "Train Epoch: 0 [2560/4138 (62%)]\tLoss: 0.000241\n",
      "Train Epoch: 0 [2880/4138 (69%)]\tLoss: 0.000238\n",
      "Train Epoch: 0 [3200/4138 (77%)]\tLoss: 0.000241\n",
      "Train Epoch: 0 [3520/4138 (85%)]\tLoss: 0.000240\n",
      "Train Epoch: 0 [3840/4138 (92%)]\tLoss: 0.000239\n",
      "Start validation...\n",
      "---len val_loader---  1260\n",
      "---target--- torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenjian/miniconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([12])\n",
      "\n",
      "Test set: Average loss: 0.0000, average diff: 675.446044921875\n",
      "\n",
      "0 th epoch time:  514.4912042617798\n",
      "1 th epoch started...\n",
      "Start training...\n",
      "Train Epoch: 1 [0/4138 (0%)]\tLoss: 0.000237\n",
      "Train Epoch: 1 [320/4138 (8%)]\tLoss: 0.000236\n",
      "Train Epoch: 1 [640/4138 (15%)]\tLoss: 0.000242\n",
      "Train Epoch: 1 [960/4138 (23%)]\tLoss: 0.000237\n",
      "Train Epoch: 1 [1280/4138 (31%)]\tLoss: 0.000238\n",
      "Train Epoch: 1 [1600/4138 (38%)]\tLoss: 0.000238\n",
      "Train Epoch: 1 [1920/4138 (46%)]\tLoss: 0.000235\n",
      "Train Epoch: 1 [2240/4138 (54%)]\tLoss: 0.000239\n",
      "Train Epoch: 1 [2560/4138 (62%)]\tLoss: 0.000235\n",
      "Train Epoch: 1 [2880/4138 (69%)]\tLoss: 0.000243\n",
      "Train Epoch: 1 [3200/4138 (77%)]\tLoss: 0.000229\n",
      "Train Epoch: 1 [3520/4138 (85%)]\tLoss: 0.000240\n",
      "Train Epoch: 1 [3840/4138 (92%)]\tLoss: 0.000234\n",
      "Start validation...\n",
      "---len val_loader---  1260\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([32])\n",
      "---target--- torch.Size([12])\n",
      "\n",
      "Test set: Average loss: 0.0000, average diff: 495.0746154785156\n",
      "\n",
      "1 th epoch time:  488.69704484939575\n",
      "2 th epoch started...\n",
      "Start training...\n",
      "Train Epoch: 2 [0/4138 (0%)]\tLoss: 0.000234\n",
      "Train Epoch: 2 [320/4138 (8%)]\tLoss: 0.000231\n",
      "Train Epoch: 2 [640/4138 (15%)]\tLoss: 0.000236\n",
      "Train Epoch: 2 [960/4138 (23%)]\tLoss: 0.000229\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "n_epochs = 10\n",
    "train_losses_all = []\n",
    "val_loss_all = []\n",
    "val_diff_all = []\n",
    "for epoch in range(n_epochs):\n",
    "    print(epoch,'th epoch started...')\n",
    "    epoch_start = time.time()\n",
    "    train_losses = train(model, train_loader, criterion, optimizer, epoch)\n",
    "    train_losses_all.append(train_losses)\n",
    "    val_loss, diff = validate(model, val_loader)\n",
    "    val_loss_all.append(val_loss)\n",
    "    val_diff_all.append(diff)\n",
    "    torch.save(model.state_dict(),\"model_trained_\" + str(epoch) + \".pt\")\n",
    "\n",
    "    train_loss_array = np.array(train_losses_all)\n",
    "    val_loss_array = np.array(val_loss_all)\n",
    "    val_diff_array = np.array(val_diff_all)\n",
    "\n",
    "    np.save(result_dir + 'train_loss_array.npy', train_loss_array)\n",
    "    np.save(result_dir + 'val_loss_array.npy', val_loss_array)\n",
    "    np.save(result_dir + 'val_diff_array.npy', val_diff_array)\n",
    "    \n",
    "    epoch_end = time.time()\n",
    "    epoch_time = epoch_end - epoch_start\n",
    "    print(epoch, 'th epoch time: ', epoch_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img_name):\n",
    "    img = Image.open(img_name)\n",
    "    img = torchvision.transforms.functional.to_tensor(img)\n",
    "    img = torchvision.transforms.functional.to_pil_image(img)\n",
    "    img = torchvision.transforms.functional.resize(img, 256)\n",
    "    five_imgs = torchvision.transforms.functional.five_crop(img, size=224)\n",
    "    img = five_imgs[4] # Center crop\n",
    "    img = torchvision.transforms.functional.to_tensor(img)\n",
    "    #print('---aaa---', img.shape)\n",
    "    batch_img = img.view(1, *(img.shape))\n",
    "    #print('---bbb---', batch_img.shape)\n",
    "    with torch.no_grad():\n",
    "        out = model(batch_img)\n",
    "        print(out)\n",
    "        pred = out.argmax()\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image as IPyImage\n",
    "img_name = '/home/wenjian/data3/wiki_crop_test/42/10004299_1908-08-19_1950.jpg'\n",
    "IPyImage(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0093, 0.0094, 0.0095, 0.0096, 0.0097, 0.0099, 0.0100, 0.0101, 0.0101,\n",
      "         0.0101, 0.0100, 0.0100, 0.0099, 0.0098, 0.0099, 0.0099, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0099, 0.0099, 0.0099, 0.0099, 0.0100,\n",
      "         0.0101, 0.0101, 0.0102, 0.0102, 0.0102, 0.0102, 0.0101, 0.0101, 0.0100,\n",
      "         0.0101, 0.0101, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0101,\n",
      "         0.0100, 0.0100, 0.0100, 0.0101, 0.0101, 0.0101, 0.0102, 0.0102, 0.0101,\n",
      "         0.0101, 0.0100, 0.0100, 0.0099, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0099, 0.0099, 0.0098, 0.0098, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0098, 0.0098,\n",
      "         0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0097, 0.0097,\n",
      "         0.0096, 0.0096, 0.0095, 0.0095, 0.0095, 0.0094, 0.0094, 0.0094, 0.0094,\n",
      "         0.0093, 0.0093]])\n",
      "tensor(40)\n"
     ]
    }
   ],
   "source": [
    "predict(model, img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([1.1, 2.5, 3.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.l1_loss(a.float() ,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
